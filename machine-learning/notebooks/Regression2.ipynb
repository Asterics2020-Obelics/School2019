{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3rd ASTERICS-OBELICS International School - Annecy, France - 8-12 April 2019\n",
    "\n",
    "### Machine Learning Tutorial\n",
    "\n",
    "# Section 4.a - Supervised Learning: regression\n",
    "by [Emille Ishida](https://www.emilleishida.com/)\n",
    "\n",
    "### *Take home message 4: representativeness matters!*\n",
    "\n",
    "**Goal:** Explore the performance of ML algorithms in different data conditions\n",
    "\n",
    "**Task**: Estimate the redshift based on photometric magnitudes  \n",
    "\n",
    "**Data**: Extract from the [Teddy photometric redshift catalog](https://github.com/COINtoolbox/photoz_catalogues)  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;First presented by [Beck et al., 2017, MNRAS, 468 (4323)](https://cosmostatistics-initiative.org/portfolio-item/representativeness-photoz/)\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5000 objects for training (teddy_A)   \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5000 objects for testing (teddy_C)  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5000 objects for testing (teddy_D)  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Features:  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$mag\\_r$: standardized r-band magnitude  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$u-g$: standardized SDSS u-g color  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$g-r$: standardized SDSS g-r color  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$r-i$: standardized SDSS r-i color  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$i-z$: standardized SDSS i-z color  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$z\\_spec$: spectroscopic redshift (label)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some basic libaries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Get the data\n",
    "\n",
    "As we already worked we with the training data before, we will go to the training directly.  \n",
    "\n",
    "PS: this is almost never a good idea!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the training data\n",
    "data_train = pd.read_csv('../../data/teddy_A.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see from the documentation that the test data is given in a separate file.  \n",
    "As a consequence, we only need to split the training data intro train and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate 80% for training and 20% for testing\n",
    "X_train, X_validation, y_train, y_validation = \\\n",
    "train_test_split(data_train[['mag_r', 'u-g', 'g-r', 'r-i', 'i-z']], data_train['z_spec'], test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now load three different test sets..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read  test sample\n",
    "teddy_b = pd.read_csv('../../data/teddy_B.csv')\n",
    "teddy_c = pd.read_csv('../../data/teddy_C.csv')\n",
    "teddy_d = pd.read_csv('../../data/teddy_D.csv')\n",
    "\n",
    "# visualize the data\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,3,1)\n",
    "sns.distplot(data_train['mag_r'], hist=False, color='black', label='Train')\n",
    "sns.distplot(teddy_b['mag_r'], hist=False, color='b', label='Teddy B')\n",
    "sns.distplot(teddy_c['mag_r'], hist=False, color='g', label='Teddy C')\n",
    "sns.distplot(teddy_d['mag_r'], hist=False, color='r', label='Teddy D')\n",
    "plt.xlabel('mag_r')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "sns.distplot(data_train['u-g'], hist=False, color='black', label='Train')\n",
    "sns.distplot(teddy_b['u-g'], hist=False, color='b', label='Teddy B')\n",
    "sns.distplot(teddy_c['u-g'], hist=False, color='g', label='Teddy C')\n",
    "sns.distplot(teddy_d['u-g'], hist=False, color='r', label='Teddy D')\n",
    "plt.xlabel('u-g')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "sns.distplot(data_train['g-r'], hist=False, color='black', label='Train')\n",
    "sns.distplot(teddy_b['g-r'], hist=False, color='b', label='Teddy B')\n",
    "sns.distplot(teddy_c['g-r'], hist=False, color='g', label='Teddy C')\n",
    "sns.distplot(teddy_d['g-r'], hist=False, color='r', label='Teddy D')\n",
    "plt.xlabel('g-r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Looking at this plots, what are your expectations?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: train a few classifiers\n",
    "\n",
    "Using [scikit-learn](https://scikit-learn.org/stable/) we are able to quickly train a set of algorithms: \n",
    "\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.a) [Linear regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# train\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# estimate the photoz\n",
    "photoz_linear_val = regr.predict(X_validation)\n",
    "\n",
    "# quality of the fit\n",
    "R2_linear_val = regr.score(X_validation, y_validation)\n",
    "R2_linear_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate the photoz\n",
    "linear_teddyb = regr.predict(teddy_b[['mag_r', 'u-g', 'g-r', 'r-i', 'i-z']])\n",
    "linear_teddyc = regr.predict(teddy_c[['mag_r', 'u-g', 'g-r', 'r-i', 'i-z']])\n",
    "linear_teddyd = regr.predict(teddy_d[['mag_r', 'u-g', 'g-r', 'r-i', 'i-z']])\n",
    "\n",
    "# quality of the fit\n",
    "R2_linear_teddyb = regr.score(teddy_b[['mag_r', 'u-g', 'g-r', 'r-i', 'i-z']], teddy_b[['z_spec']])\n",
    "R2_linear_teddyc = regr.score(teddy_c[['mag_r', 'u-g', 'g-r', 'r-i', 'i-z']], teddy_c[['z_spec']])\n",
    "R2_linear_teddyd = regr.score(teddy_d[['mag_r', 'u-g', 'g-r', 'r-i', 'i-z']], teddy_d[['z_spec']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' Linear regression results')\n",
    "print('Teddy B: ', R2_linear_teddyb)\n",
    "print('Teddy C: ', R2_linear_teddyc)\n",
    "print('Teddy D: ', R2_linear_teddyd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot result\n",
    "sns.set_style('ticks')\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.title('Teddy catalog: A-> B, Linear reg. score: ' + str(round(R2_linear_teddyb,2)))\n",
    "plt.scatter(teddy_b[['z_spec']], linear_teddyb, marker='x')\n",
    "plt.plot([0,0.65], [0,0.65], color='red', lw=2, ls='--')\n",
    "plt.xlabel('true redshift')\n",
    "plt.ylabel('estimated redshift')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.title('Teddy catalog: A-> C, Linear reg. score: ' + str(round(R2_linear_teddyc,2)))\n",
    "plt.scatter(teddy_c[['z_spec']], linear_teddyc, marker='x')\n",
    "plt.plot([0,0.65], [0,0.65], color='red', lw=2, ls='--')\n",
    "plt.xlabel('true redshift')\n",
    "plt.ylabel('estimated redshift')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.title('Teddy catalog: A-> D, Linear reg. score: ' + str(round(R2_linear_teddyd,2)))\n",
    "plt.scatter(teddy_d[['z_spec']], linear_teddyd, marker='x')\n",
    "plt.plot([0,1], [0,1], color='red', lw=2, ls='--')\n",
    "plt.xlabel('true redshift')\n",
    "plt.ylabel('estimated redshift')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check why the scores for Teddy D are higher despite of the obvious outliers: [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.b) [Nearest Neighbor](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html):\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Here we have a little more room for improvement.  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Try changing the number of neighbors, or other parameters (check documentation), to improve the quality of the fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# choose number of neighbors\n",
    "nn = 9\n",
    "\n",
    "# initiate a KNN instance\n",
    "knn = KNeighborsRegressor(n_neighbors=nn)\n",
    "\n",
    "# fit the model using training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# estimate photometric redshift for the validation data\n",
    "photoz_knn_validation = knn.predict(X_validation)\n",
    "\n",
    "# quality of the fit\n",
    "R2_knn_val = knn.score(X_validation, y_validation)\n",
    "R2_knn_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you are happy with the optimization, estimate the photometric redshift values for the test sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate the photoz\n",
    "knn_teddyb = knn.predict(teddy_b[['mag_r', 'u-g', 'g-r', 'r-i', 'i-z']])\n",
    "knn_teddyc = knn.predict(teddy_c[['mag_r', 'u-g', 'g-r', 'r-i', 'i-z']])\n",
    "knn_teddyd = knn.predict(teddy_d[['mag_r', 'u-g', 'g-r', 'r-i', 'i-z']])\n",
    "\n",
    "# quality of the fit\n",
    "R2_knn_teddyb = knn.score(teddy_b[['mag_r', 'u-g', 'g-r', 'r-i', 'i-z']], teddy_b[['z_spec']])\n",
    "R2_knn_teddyc = knn.score(teddy_c[['mag_r', 'u-g', 'g-r', 'r-i', 'i-z']], teddy_c[['z_spec']])\n",
    "R2_knn_teddyd = knn.score(teddy_d[['mag_r', 'u-g', 'g-r', 'r-i', 'i-z']], teddy_d[['z_spec']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' KNN regression results')\n",
    "print('Teddy B: ', R2_knn_teddyb)\n",
    "print('Teddy C: ', R2_knn_teddyc)\n",
    "print('Teddy D: ', R2_knn_teddyd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot result\n",
    "sns.set_style('ticks')\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.title('Teddy catalog: A-> B, knn score: ' + str(round(R2_knn_teddyb,2)))\n",
    "plt.scatter(teddy_b[['z_spec']], knn_teddyb, marker='x')\n",
    "plt.plot([0,0.65], [0,0.65], color='red', lw=2, ls='--')\n",
    "plt.xlabel('true redshift')\n",
    "plt.ylabel('estimated redshift')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.title('Teddy catalog: A-> C, knn score: ' + str(round(R2_knn_teddyc,2)))\n",
    "plt.scatter(teddy_c[['z_spec']], knn_teddyc, marker='x')\n",
    "plt.plot([0,0.65], [0,0.65], color='red', lw=2, ls='--')\n",
    "plt.xlabel('true redshift')\n",
    "plt.ylabel('estimated redshift')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.title('Teddy catalog: A-> D, knn score: ' + str(round(R2_knn_teddyd,2)))\n",
    "plt.scatter(teddy_d[['z_spec']], knn_teddyd, marker='x')\n",
    "plt.plot([0,1], [0,1], color='red', lw=2, ls='--')\n",
    "plt.xlabel('true redshift')\n",
    "plt.ylabel('estimated redshift')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.c) [Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html):\n",
    "\n",
    "Here we have still more freedom. To begin with, try playing with the number of trees in your forest and the maximum depth allowed for each tree.  \n",
    "**How do your regression results change?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# choose number of trees in the forest\n",
    "n_trees = 100\n",
    "\n",
    "# define maximum depth, None=> split continues until the leafs are pure\n",
    "depth = 8\n",
    "\n",
    "# initiate a Random Forest instance\n",
    "randfor = RandomForestRegressor(max_depth=depth, n_estimators=n_trees)\n",
    "\n",
    "# train the model\n",
    "randfor.fit(X_train, y_train)\n",
    "\n",
    "# estimate the photometric redshift for the validation sample\n",
    "photoz_randforest_validation = randfor.predict(X_validation)\n",
    "\n",
    "# quality of the fit\n",
    "R2_randforest_val = randfor.score(X_validation, y_validation)\n",
    "R2_randforest_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are satisfied, see how your regression perform in the test sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate the photoz\n",
    "randfor_teddyb = randfor.predict(teddy_b[['mag_r', 'u-g', 'g-r', 'r-i', 'i-z']])\n",
    "randfor_teddyc = randfor.predict(teddy_c[['mag_r', 'u-g', 'g-r', 'r-i', 'i-z']])\n",
    "randfor_teddyd = randfor.predict(teddy_d[['mag_r', 'u-g', 'g-r', 'r-i', 'i-z']])\n",
    "\n",
    "# quality of the fit\n",
    "R2_randfor_teddyb = randfor.score(teddy_b[['mag_r', 'u-g', 'g-r', 'r-i', 'i-z']], teddy_b[['z_spec']])\n",
    "R2_randfor_teddyc = randfor.score(teddy_c[['mag_r', 'u-g', 'g-r', 'r-i', 'i-z']], teddy_c[['z_spec']])\n",
    "R2_randfor_teddyd = randfor.score(teddy_d[['mag_r', 'u-g', 'g-r', 'r-i', 'i-z']], teddy_d[['z_spec']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' Random Forest regression results')\n",
    "print('Teddy B: ', R2_randfor_teddyb)\n",
    "print('Teddy C: ', R2_randfor_teddyc)\n",
    "print('Teddy D: ', R2_randfor_teddyd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot result\n",
    "sns.set_style('ticks')\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.title('Teddy catalog: A-> B, RF score: ' + str(round(R2_randfor_teddyb,2)))\n",
    "plt.scatter(teddy_b[['z_spec']], randfor_teddyb, marker='x')\n",
    "plt.plot([0,0.65], [0,0.65], color='red', lw=2, ls='--')\n",
    "plt.xlabel('true redshift')\n",
    "plt.ylabel('estimated redshift')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.title('Teddy catalog: A-> C, RF score: ' + str(round(R2_randfor_teddyc,2)))\n",
    "plt.scatter(teddy_c[['z_spec']], randfor_teddyc, marker='x')\n",
    "plt.plot([0,0.65], [0,0.65], color='red', lw=2, ls='--')\n",
    "plt.xlabel('true redshift')\n",
    "plt.ylabel('estimated redshift')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.title('Teddy catalog: A-> D, RF score: ' + str(round(R2_randfor_teddyd,2)))\n",
    "plt.scatter(teddy_d[['z_spec']], randfor_teddyd, marker='x')\n",
    "plt.plot([0,1], [0,1], color='red', lw=2, ls='--')\n",
    "plt.xlabel('true redshift')\n",
    "plt.ylabel('estimated redshift')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
