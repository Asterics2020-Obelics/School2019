{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning for galaxy deblending\n",
    "\n",
    "##### Alexandre Boucaud (APC) & Marc Huertas-Company (LERMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Introduction](#Introduction)\n",
    "2. [Data](#Data)\n",
    "3. [Workflow](#Workflow)\n",
    "4. [Evaluation](#Detection-evaluation)\n",
    "5. [Local testing/exploration](#Local-testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In astronomical images, the projection effects may cause two or more galaxies to overlap. When they are barely indistinguishable from one another, they are referred to as _blended_ and this can bias astrophysical estimators such as the morphology of galaxies or the shear (weak gravitational lensing distortion).  \n",
    "As the sensitivity of imaging devices grows, a high fraction of galaxies appear _blended_ in the images, which is a known and important issue for current and upcoming galaxy surveys.  \n",
    "\n",
    "In order not to discard such a wealth of information, it is key to develop methods to enable astronomers to alleviate such effect.\n",
    "We can foresee some features that would help, in which machine learning could provide a solution:\n",
    "- classify an image as containing isolated/blended objects  \n",
    "  ___binary classification___\n",
    "- count the number of blended sources in a blended image  \n",
    "  ___regression / object detection___\n",
    "- find the contours of each object  \n",
    "  ___object detection/segmentation___\n",
    "- ...\n",
    "\n",
    "In this exercice, we will approach the third item, the detection of contours, but in a constrained way : the images will only contain **two galaxies** and the goal will be to find the **contours of the central galaxy**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code\n",
    "\n",
    "Install the `dltools` lib that contains helper methods for training a deep neural network on the provided blended galaxy dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/aboucaud/deeplearning4astro_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dltools.detector import ObjectDetector\n",
    "from dltools.metric import iou_bitmap\n",
    "from dltools.plots import plot_history\n",
    "from dltools.plots import plot_random_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"data\"\n",
    "# Use the big dataset (during the school, use this only on Colab, otherwise set to False)\n",
    "full = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://www.apc.univ-paris7.fr/Downloads/comput/aboucaud\"\n",
    "FOLDER = \"ed127\"\n",
    "FILES = [\n",
    "    \"test_blends_mini.npy\",\n",
    "    \"test_target_masks_mini.npy\",\n",
    "    \"train_blends_mini.npy\",\n",
    "    \"train_target_masks_mini.npy\",\n",
    "\n",
    "]\n",
    "BIG_FILES = [\n",
    "    \"masks.tar.gz\",\n",
    "    \"blends.tar.gz\",\n",
    "]\n",
    "\n",
    "def main(output_dir, delete_archive=False, full=False):\n",
    "    if full:\n",
    "        files = BIG_FILES\n",
    "    else:\n",
    "        files = FILES\n",
    "\n",
    "    urls = [\n",
    "        f\"{URL}/{FOLDER}/{filename}\"\n",
    "        for filename in files\n",
    "    ]\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        print(f\"Creating directory {output_dir}\")\n",
    "        os.mkdir(output_dir)\n",
    "\n",
    "    for url, filename in zip(urls, files):\n",
    "        output_file = os.path.join(output_dir, filename)\n",
    "\n",
    "        if os.path.exists(output_file):\n",
    "            print(f\"{filename} already downloaded.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Downloading from {url} ...\")\n",
    "        urlretrieve(url, filename=output_file)\n",
    "        print(f\"=> File saved as {output_file}\")\n",
    "\n",
    "        if filename.endswith(\"tar.gz\"):\n",
    "            print(\"Extracting tarball..\")\n",
    "            with tarfile.open(output_file, \"r:gz\") as f:\n",
    "                f.extractall(output_dir)\n",
    "            print(\"Done.\")\n",
    "\n",
    "            if delete_archive:\n",
    "                os.remove(output_file)\n",
    "                print(f\"=> File {output_file} removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(output_dir=datadir, full=full, delete_archive=True)                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the train and test datasets in memory-mapping mode. This does not actually load the data into memory but creates a mapping to it to easily retrieve chunks of the data using its indices when needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = \"\" if full else \"_mini\"\n",
    "\n",
    "X_train = np.load(os.path.join(datadir, f\"train_blends{suffix}.npy\"), mmap_mode='r')\n",
    "Y_train = np.load(os.path.join(datadir, f\"train_target_masks{suffix}.npy\"), mmap_mode='r')[:, 1, :, :]\n",
    "\n",
    "X_test = np.load(os.path.join(datadir, f\"test_blends{suffix}.npy\"), mmap_mode='r')\n",
    "Y_test = np.load(os.path.join(datadir, f\"test_target_masks{suffix}.npy\"), mmap_mode='r')[:, 1, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_basic(idx):\n",
    "    titles = [\n",
    "        'blended galaxies',\n",
    "        'segmap of companion galaxy'\n",
    "    ]\n",
    "\n",
    "    fig_size = (12, 6)\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=fig_size)\n",
    "    axes[0].imshow(X_train[idx], cmap='viridis')\n",
    "    axes[1].imshow(Y_train[idx], cmap='Greys_r')\n",
    "    for title, ax in zip(titles, axes):\n",
    "        ax.set_title(title)\n",
    "        ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.random.randint(len(X_train))\n",
    "plot_data_basic(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal in this exercise is to create a deep learning model that produces the segmentation map (mask) of the companion galaxy from the image of the blend. This can be seen as a classification task where each pixel of the image has to be classified as \"galaxy companion\" or \"not galaxy companion\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow\n",
    "\n",
    "In the `dltools` package we have implemented a class called `ObjectDetector`, with two main methods implemented : `fit()` and `predict()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However `ObjectDetector` is missing a model that **you need to provide**. You can have a look at how the ObjectDetector was implemented to run your model. It will give you an idea of how to organize your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ObjectDetector??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model needs to take the image blend as input and produce an other image as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection evaluation\n",
    "\n",
    "For image detection a classical metric is the ***Intersection over Union (IoU)*** also referred to as ***Jaccard index*** and defined as\n",
    "\n",
    "$$ IoU(A, B) =  \\dfrac{|A \\cap B|}{|A \\cup B|} $$\n",
    "\n",
    "This metric is very sensitive to small shifts or area difference between truth and prediction.\n",
    "\n",
    "Typically, a value of IoU superior to 0.5 is used to define a good detection.\n",
    "\n",
    "An implementation of the IoU for a series of flatten segmentation images $\\in [0, 1]$ can be found in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_bitmap??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the metric used to score the segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "The model is the part where you intervention is needed. A very basic (working) model is implemented below. It has two convolution layers. While it is very fast to train, it does not yield good results.\n",
    "\n",
    "Try to navigate the web/github to find appropriate models for this image segmentation task. Or build upon this existing model by complexifying it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE HERE\n",
    "# ===========\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import (\n",
    "    Conv2D,\n",
    "    Dropout,\n",
    "    Input,\n",
    "    MaxPooling2D,\n",
    "    concatenate,\n",
    "    Conv2DTranspose,\n",
    "    UpSampling2D,\n",
    ")\n",
    "from keras.layers.noise import GaussianNoise\n",
    "\n",
    "input_shape = (128, 128, 1)\n",
    "output_channels = 1\n",
    "last_activation = \"sigmoid\"\n",
    "\n",
    "def model():\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Conv2D(\n",
    "            15, (3, 3), \n",
    "            input_shape=input_shape,\n",
    "            activation=\"relu\", \n",
    "            padding=\"same\",\n",
    "        )\n",
    "    )\n",
    "    model.add(\n",
    "        Conv2D(\n",
    "            output_channels, (3, 3), \n",
    "            activation=last_activation,\n",
    "            padding=\"same\", \n",
    "        )\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE HERE THE NUMBER OF EPOCHS OR THE BATCH SIZE\n",
    "obj = ObjectDetector(model(), batch_size=16, epoch=10, model_check_point=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = obj.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on the test set and score the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = obj.predict_score(X_test.squeeze(), Y_test)\n",
    "\n",
    "print(f\"Score: {score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "plot_random_results(obj.model_, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise : modify the model and iterate\n",
    "\n",
    "## GOOD LUCK !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
