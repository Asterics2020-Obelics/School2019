{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning for galaxy deblending\n",
    "\n",
    "##### Alexandre Boucaud (APC) & Marc Huertas-Company (LERMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Introduction](#Introduction)\n",
    "2. [Data](#Data)\n",
    "3. [Workflow](#Workflow)\n",
    "4. [Evaluation](#Detection-evaluation)\n",
    "5. [Local testing/exploration](#Local-testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In astronomical images, the projection effects may cause two or more galaxies to overlap. When they are barely indistinguishable from one another, they are referred to as _blended_ and this can bias astrophysical estimators such as the morphology of galaxies or the shear (weak gravitational lensing distortion).  \n",
    "As the sensitivity of imaging devices grows, a high fraction of galaxies appear _blended_ in the images, which is a known and important issue for current and upcoming galaxy surveys.  \n",
    "\n",
    "In order not to discard such a wealth of information, it is key to develop methods to enable astronomers to alleviate such effect.\n",
    "We can foresee some features that would help, in which machine learning could provide a solution:\n",
    "- classify an image as containing isolated/blended objects  \n",
    "  ___binary classification___\n",
    "- count the number of blended sources in a blended image  \n",
    "  ___regression / object detection___\n",
    "- find the contours of each object  \n",
    "  ___object detection/segmentation___\n",
    "- ...\n",
    "\n",
    "In this exercice, we will approach the third item, the detection of contours, but in a constrained way : the images will only contain **two galaxies** and the goal will be to find the **contours of the central galaxy**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code\n",
    "\n",
    "Install the `dltools` lib that contains helper methods for training a deep neural network on the provided blended galaxy dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/aboucaud/deeplearning4astro_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"data\"\n",
    "# Use the big dataset (during the school, use this only on Colab, otherwise set to False)\n",
    "full = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://www.apc.univ-paris7.fr/Downloads/comput/aboucaud\"\n",
    "FOLDER = \"ed127\"\n",
    "FILES = [\n",
    "    \"test_blends_mini.npy\",\n",
    "    \"test_target_img_mini.npy\",\n",
    "    \"test_target_masks_mini.npy\",\n",
    "    \"train_blends_mini.npy\",\n",
    "    \"train_target_img_mini.npy\",\n",
    "    \"train_target_masks_mini.npy\",\n",
    "\n",
    "]\n",
    "BIG_FILES = [\n",
    "    \"masks.tar.gz\",\n",
    "    \"single_imgs.tar.gz\",\n",
    "    \"blends.tar.gz\",\n",
    "]\n",
    "\n",
    "def main(output_dir, delete_archive=False, full=False):\n",
    "    if full:\n",
    "        files = BIG_FILES\n",
    "    else:\n",
    "        files = FILES\n",
    "\n",
    "    urls = [\n",
    "        f\"{URL}/{FOLDER}/{filename}\"\n",
    "        for filename in files\n",
    "    ]\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        print(f\"Creating directory {output_dir}\")\n",
    "        os.mkdir(output_dir)\n",
    "\n",
    "    for url, filename in zip(urls, files):\n",
    "        output_file = os.path.join(output_dir, filename)\n",
    "\n",
    "        if os.path.exists(output_file):\n",
    "            print(f\"{filename} already downloaded.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Downloading from {url} ...\")\n",
    "        urlretrieve(url, filename=output_file)\n",
    "        print(f\"=> File saved as {output_file}\")\n",
    "\n",
    "        if filename.endswith(\"tar.gz\"):\n",
    "            print(\"Extracting tarball..\")\n",
    "            with tarfile.open(output_file, \"r:gz\") as f:\n",
    "                f.extractall(output_dir)\n",
    "            print(\"Done.\")\n",
    "\n",
    "            if delete_archive:\n",
    "                os.remove(output_file)\n",
    "                print(f\"=> File {output_file} removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(output_dir=datadir, full=full, delete_archive=True)                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the train and test datasets in memory-mapping mode. This does not actually load the data into memory but creates a mapping to it to easily retrieve chunks of the data using its indices when needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = \"\" if full else \"_mini\"\n",
    "\n",
    "X_train = np.load(os.path.join(datadir, f\"train_blends{suffix}.npy\"), mmap_mode='r')\n",
    "Y_train = np.load(os.path.join(datadir, f\"train_target_masks{suffix}.npy\"), mmap_mode='r')\n",
    "\n",
    "X_test = np.load(os.path.join(datadir, f\"test_blends{suffix}.npy\"), mmap_mode='r')\n",
    "Y_test = np.load(os.path.join(datadir, f\"test_target_masks{suffix}.npy\"), mmap_mode='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE HERE\n",
    "# ===========\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import (\n",
    "    Conv2D,\n",
    "    Dropout,\n",
    "    Input,\n",
    "    MaxPooling2D,\n",
    "    concatenate,\n",
    "    Conv2DTranspose,\n",
    "    UpSampling2D,\n",
    ")\n",
    "from keras.layers.noise import GaussianNoise\n",
    "\n",
    "input_shape = (128, 128, 1)\n",
    "output_channels = 1\n",
    "last_activation = \"sigmoid\"\n",
    "\n",
    "def model():\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Conv2D(\n",
    "            15, (3, 3), \n",
    "            input_shape=input_shape,\n",
    "            activation=\"relu\", \n",
    "            padding=\"same\",\n",
    "        )\n",
    "    )\n",
    "    model.add(\n",
    "        Conv2D(\n",
    "            output_channels, (3, 3), \n",
    "            activation=last_activation,\n",
    "            padding=\"same\", \n",
    "        )\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dltools.detector import ObjectDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE HERE THE NUMBER OF EPOCHS OR THE BATCH SIZE\n",
    "obj = ObjectDetector(model(), batch_size=16, epoch=10, model_check_point=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = obj.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on the test set and score the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = obj.predict_score(X_test.squeeze(), Y_test)\n",
    "\n",
    "print(f\"Score: {score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "from dltools.plots import plot_history\n",
    "from dltools.plots import plot_random_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "plot_random_results(obj.model_, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise : modify the model and iterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
