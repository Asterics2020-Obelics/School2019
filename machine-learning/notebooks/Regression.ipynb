{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3rd ASTERICS-OBELICS International School - Annecy, France - 8-12 April 2019\n",
    "\n",
    "### Machine Learning Tutorial\n",
    "\n",
    "# Section 1.c - Supervised Learning: regression\n",
    "by [Emille Ishida](https://www.emilleishida.com/)\n",
    "\n",
    "### *Take home message 3: choosing a machine learning algorithm is an art!*\n",
    "\n",
    "**Goal:** Get acquainted with basic machine learning algorithms for regression\n",
    "\n",
    "**Task**: Estimate the redshift based on photometric magnitudes  \n",
    "\n",
    "**Data**: Extract from the [Teddy photometric redshift catalog](https://github.com/COINtoolbox/photoz_catalogues)  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;First presented by [Beck et al., 2017, MNRAS, 468 (4323)](https://cosmostatistics-initiative.org/portfolio-item/representativeness-photoz/)\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5000 objects for training (teddy_A)  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5000 objects for testing (teddy_B)  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Features:  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$mag\\_r$: standardized r-band magnitude  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$u-g$: standardized SDSS u-g color  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$g-r$: standardized SDSS g-r color  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$r-i$: standardized SDSS r-i color  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$i-z$: standardized SDSS i-z color  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$z\\_spec$: spectroscopic redshift (label)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some basic libaries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Digest the data\n",
    "\n",
    "As always, we start by loading and visualizing the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "data = pd.read_csv('../data/teddy_A.csv')\n",
    "\n",
    "# check available columns (features)\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dimensionality of the data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see from the documentation that the test data is given in a separate file.  \n",
    "As a consequence, we only need to split the training data intro train and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate 80% for training and 20% for testing\n",
    "\n",
    "# check your samples (size, features, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data\n",
    "g = sns.PairGrid(data, diag_sharey=False)\n",
    "g.map_lower(sns.kdeplot)                      \n",
    "g.map_upper(sns.scatterplot)\n",
    "g.map_diag(sns.kdeplot, lw=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: train a few classifiers\n",
    "\n",
    "Using [scikit-learn](https://scikit-learn.org/stable/) we are able to quickly train a set of algorithms: \n",
    "\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.a) [Linear regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# train\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# estimate the photoz\n",
    "photoz_linear_val = regr.predict(X_validation)\n",
    "\n",
    "# quality of the fit\n",
    "R2_linear_val = regr.score(X_validation, y_validation)\n",
    "R2_linear_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is not much more to optimize in this simple model, so we can use the trained algorithm to estimate the redshift in the test sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read  test sample\n",
    "data_test = pd.read_csv('../data/teddy_B.csv')\n",
    "\n",
    "# check the features\n",
    "data_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate the photoz\n",
    "photoz_linear_test = regr.predict(data_test[['mag_r', 'u-g', 'g-r', 'r-i', 'i-z']])\n",
    "\n",
    "# quality of the fit\n",
    "R2_linear_test = regr.score(data_test[['mag_r', 'u-g', 'g-r', 'r-i', 'i-z']], data_test[['z_spec']])\n",
    "R2_linear_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot result\n",
    "sns.set_style('ticks')\n",
    "fig = plt.figure()\n",
    "plt.title('Teddy catalog: A-> B, Linear reg. score: ' + str(round(R2_linear_test,2)))\n",
    "plt.scatter(data_test[['z_spec']], photoz_linear_test, marker='x')\n",
    "plt.plot([0,0.65], [0,0.65], color='red', lw=2, ls='--')\n",
    "plt.xlabel('true redshift')\n",
    "plt.ylabel('estimated redshift')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.b) [Nearest Neighbor](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html):\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Here we have a little more room for improvement.  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Try changing the number of neighbors, or other parameters (check documentation), to improve the quality of the fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# choose number of neighbors\n",
    "nn = 9\n",
    "\n",
    "# initiate a KNN instance\n",
    "\n",
    "# fit the model using training data\n",
    "\n",
    "# estimate photometric redshift for the validation data\n",
    "\n",
    "# quality of the fit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you are happy with the optimization, estimate the photometric redshift values for the test sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate the photoz\n",
    "\n",
    "# quality of the fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.c) [Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html):\n",
    "\n",
    "Here we have still more freedom. To begin with, try playing with the number of trees in your forest and the maximum depth allowed for each tree.  \n",
    "**How do your regression results change?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# choose number of trees in the forest\n",
    "n_trees =\n",
    "\n",
    "# define maximum depth, None=> split continues until the leafs are pure\n",
    "depth = \n",
    "\n",
    "# initiate a Random Forest instance\n",
    "\n",
    "# train the model\n",
    "\n",
    "\n",
    "# estimate the photometric redshift for the validation sample\n",
    "\n",
    "# quality of the fit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are satisfied, see how your regression perform in the test sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate the photoz\n",
    "\n",
    "# quality of the fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ... few free to try other algorithms if you wish to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Compare results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the results we have so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('                         Test sample   Validation sample')\n",
    "print('Linear regression: ', R2_linear_test, R2_linear_val)\n",
    "print('kNN:               ', R2_knn_test, R2_knn_val)\n",
    "print('Random Forest:     ', R2_randforest_test, R2_randforest_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results seem pretty stable, which give us still another ensurance that the results from the machine learning algorithms are consistent.\n",
    "\n",
    "**Can you guess what characteristics of the data helps this stability?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Food for thought:\n",
    "\n",
    "In the `data` folder of the github repository there are other 2 files: `teddy_C` and `teddy_D`.   \n",
    "This files should be used only for testing.  \n",
    "\n",
    "Try applying your trained regression models in these data sets and compare the results with the ones above. \n",
    "\n",
    "As always, remember to weight your expectations before you start.\n",
    "\n",
    "**Are the results any different? If so, can you guess why?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
